{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b3e546-296c-4d7e-b8c3-cac7280db97f",
   "metadata": {},
   "source": [
    "# Pipelines (preprocessing to estimator), CV, Gridsearch\n",
    "\n",
    "- [ ] how to do: preprocessing (with `ColumnTransformer`)\n",
    "- [ ] how to examine: preprecessing\n",
    "- [ ] how to do: pipelines + cross validation + scoring\n",
    "    - `make_pipeline()` with preprocessing and estimator\n",
    "    - examine pipeline elements \n",
    "    - fit and predict using the pipeline (not CV)\n",
    "    - examine the pipeline using CV (using the cv function and examining its output)\n",
    "- [ ] scoring vocab: recall/sensitivity, precision, specificity, accuracy, \n",
    "- [ ] how to do: optimizing a pipeline by \"tuning the hyperparameters\"\n",
    "    - hyperparameters are the parameters of functions/estimators in the steps in your pipeline\n",
    "    - set up and use `gridsearchCV`\n",
    "    - examine output of `gridsearchCV`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e8ccb8c-f508-4022-bbca-f3a03311a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from df_after_transform import df_after_transform\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")  # display='text' is the default\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000, 'display.max_rows', 50, 'display.max_columns', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdaf8d-899f-41f5-b520-79da9c5284d5",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5771be6-0588-440b-b738-5a55f50bb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('inputs/2013_subsample.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81a81b-7e5d-4483-a987-90e2fd8c70d3",
   "metadata": {},
   "source": [
    "## Create the training and holdout samples\n",
    "\n",
    "Split your data into test and train. Your options:\n",
    "- [sklearn has some built in splitters](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "    - These are rarely the best optios for real world data. Prediction is often about the future!\n",
    "- [`test_train_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) can do basic splits, but may not be appropriate\n",
    "    - _test_ is the typical sklearn vernacular, on the website I call this this holdout sample\n",
    "- You can just keep the most recent time period of your samples in the holdout and put the rest into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef9807f9-3c31-48bd-b380-701d5f99b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to test and train (what we call the \"test\" subset here is the \"holdout\" data)\n",
    "\n",
    "# first let's separate y from X (as is typically done)\n",
    "y = loans.loan_status == 'Charged Off'\n",
    "y.value_counts()\n",
    "loans = loans.drop('loan_status',axis=1)\n",
    "\n",
    "# stratify will make sure that test/train both have equal fractions of outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans, y, stratify=y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7e8a4-0496-4706-8c20-4ab4b4754642",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "On the **TRAINING DATA ONLY**: \n",
    "- do lots of EDA\n",
    "- look for missing values, which variables are what type, and outliers \n",
    "- figure out how you'd clean the data (imputation, scaling, encoding categorical vars)\n",
    "- these lessons will go into the preprocessinG portion of your pipeline \n",
    "- PRO TIP: `pandas-profiling` and `dabl` build automated reports. Which is nice, but remember you need to examine them closely! **There is no shortcut for EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83ecffc0-43bb-4b20-836e-4a9b72922635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport # now use ydata-profiling\n",
    "# \n",
    "# profile = ProfileReport(pd.concat([y_train, X_train], axis=1), \n",
    "#                         title='Lending Club Profiling Report',\n",
    "#                         html={'style':{'full_width':True}}) \n",
    "# profile.to_file(\"inputs/lending_club_EDA_training.html\") # can take a minute or two with this dataset size. Let's look at the one I uploaded...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90522f-d069-4649-ad7c-32aa03ae3d4a",
   "metadata": {},
   "source": [
    "## NOW LET'S LEARN EACH PART OF \"Optimize a series of models\" FROM THE TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad9a34-752b-4282-a7d0-ce03e86ae572",
   "metadata": {},
   "source": [
    "### Steps 1 and 2: Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bedb4dc4-f531-4f95-be76-9e3e8e30b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline to clean each type of variable (1 pipe per var type)\n",
    "\n",
    "numer_pipe = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                           StandardScaler()) \n",
    "\n",
    "cat_pipe   = make_pipeline(OneHotEncoder(drop='first'))\n",
    "\n",
    "# combine those pipes into \"preprocess\" pipe\n",
    "\n",
    "preproc_pipe = ColumnTransformer(  \n",
    "    [ # arg 1 of ColumnTransformer is a list, so this starts the list\n",
    "    # a tuple for the numerical vars: name, pipe, which vars to apply to\n",
    "    (\"num_impute\", numer_pipe, ['annual_inc']),\n",
    "    # a tuple for the categorical vars: name, pipe, which vars to apply to\n",
    "    (\"cat_trans\", cat_pipe, ['grade'])\n",
    "    ]\n",
    "    , # ColumnTransformer can take other args, most important: \"remainder\"\n",
    "    remainder = 'drop' # you either drop or passthrough any vars not modified above\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9deeb97-af7d-4068-a75d-cecf2b36f5a1",
   "metadata": {},
   "source": [
    "_Note: You can have multiple \"numeric pipes\" or \"cat pipes\" if you think some number variables should receive different treatments, which is very common!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4da2b19a-887d-404f-b212-dcfb527b6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 columns in the preprocessed data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>121.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_B</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_C</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_D</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_E</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_F</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_G</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  mean   std   min   25%   50%   75%     max\n",
       "annual_inc  107843.0  0.00  1.00 -1.36 -0.55 -0.19  0.32  121.55\n",
       "grade_B     107843.0  0.33  0.47  0.00  0.00  0.00  1.00    1.00\n",
       "grade_C     107843.0  0.28  0.45  0.00  0.00  0.00  1.00    1.00\n",
       "grade_D     107843.0  0.15  0.36  0.00  0.00  0.00  0.00    1.00\n",
       "grade_E     107843.0  0.07  0.25  0.00  0.00  0.00  0.00    1.00\n",
       "grade_F     107843.0  0.03  0.18  0.00  0.00  0.00  0.00    1.00\n",
       "grade_G     107843.0  0.01  0.08  0.00  0.00  0.00  0.00    1.00"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# hot tip: check out what this preprocessing does before you continue!\n",
    "###########\n",
    "\n",
    "from df_after_transform import df_after_transform\n",
    "\n",
    "preproc_df = df_after_transform(preproc_pipe,X_train)\n",
    "print(f'There are {preproc_df.shape[1]} columns in the preprocessed data.')\n",
    "preproc_df.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c09ac5-fa1a-47fd-bd15-8af652ef4c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "1. How many observations for `annual_inc` were non-missing before the processing? Does our imputation choice here we make a small or large impact?\n",
    "1. How many values of `grade` was there in the data before and after `preproc_pipe`? \n",
    "1. Above, revise `preproc_pipe` to include another continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24b6dc05-99ea-49bd-87ad-d18072190b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0ae66-ac2e-4808-b4aa-46ba4991e356",
   "metadata": {},
   "source": [
    "### Prof demo: Fitting and using ONE model\n",
    "\n",
    "Warning: This is not best practice to do on the whole training sample. The point here is to simply show you how to estimate and use a model.\n",
    "\n",
    "_(The only time you fit a model on the whole training sample is the VERY end of the template, right before you check to see how it does on the holdout.)_\n",
    "\n",
    "Steps: https://ledatascifi.github.io/ledatascifi-2022/content/05/04c_onemodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7cb00-5ba2-4c3a-a3f6-39a83f5656dc",
   "metadata": {},
   "source": [
    "To fit the model: `<model>.fit(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8880e9f2-2c72-4e84-b995-908fd503cc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create (\"instantiate\") the estimator class with some hyperparameters,\n",
    "# note: the hypermeters are whatever is inside the \"()\"\n",
    "# assign this instance of the estimator to an object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# fit the model to the data: <model>.fit(X,y)\n",
    "# note: I'm only using annual income here for illustration\n",
    "logit.fit(X_train[['annual_inc']], \n",
    "          y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34622e51-07a4-4ebc-9b6b-e8ae940ee7ce",
   "metadata": {},
   "source": [
    "To use the model: `<model>.predict(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ce3fcc4-b5f2-4242-8781-2bdf71c4f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% predicted as charge offs: 0.0\n",
      "Accuracy:                   84.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this creates predicted values \n",
    "y_pred = logit.predict(X_train[['annual_inc']],)\n",
    "\n",
    "print(f'''\n",
    "% predicted as charge offs: {round(100*(y_pred == 1).mean(),2)}\n",
    "Accuracy:                   {round(100*(y_pred == y_train).mean(),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f9e05-1695-4711-a4bb-d5c4db4b8dcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "- Q4: Let's estimate a different logit model, and see if the accuracy or the number of predictions of charge offs changes. [This time change the penalty OR the value of \"C\".](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18af2527-5d12-47d1-adb9-20fc836a3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12edbc63-87fc-4c75-89ef-9ffa36142a90",
   "metadata": {},
   "source": [
    "### Steps 3, 4, and 5: Pipelines, CV, and model evaluation (scoring)\n",
    "\n",
    "Making a pipeline is easy: `make_pipeline` will put steps together for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77585a80-f73c-48b1-babd-7d6cef833911",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = make_pipeline(preproc_pipe, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81d990-05ff-4d1e-ab7e-a9e660669ee0",
   "metadata": {},
   "source": [
    "A pipeline is an object that stores its steps (and steps within steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d75b93e3-9e04-4e41-8e1a-c0506fbfa1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704d1f0-07fc-4834-b7c0-5e2776d95160",
   "metadata": {},
   "source": [
    "Fitting the model and using it is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d7616d7-8203-4f3d-b5aa-8952212f8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% predicted as charge offs: 0.0\n",
      "Accuracy:                   84.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_pipe.fit(X_train, y_train) \n",
    "y_pred = logit_pipe.predict(X_train)\n",
    "\n",
    "print(f'''\n",
    "% predicted as charge offs: {round(100*(y_pred == 1).mean(),2)}\n",
    "Accuracy:                   {round(100*(y_pred == y_train).mean(),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247024f0-3bcb-4b66-a4a1-a8444eb530f4",
   "metadata": {},
   "source": [
    "But the better idea is to see how that model does on different \"folds\" of the data: CROSS VALIDATION.\n",
    "\n",
    "The [`cross_validate` (function docs here)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html?highlight=cross_validate#sklearn.model_selection.cross_validate) makes this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c1c4666-6da0-4d77-8de4-0a8b19ab9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(logit_pipe,\n",
    "                        X_train, y_train,\n",
    "                        scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd878ec-0312-4fb2-8b9b-cab993ec233f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "- Q5: What is the average score of this model in the folds?\n",
    "- Q6: How many folds did we use above (by default). Change to 10 folds and repeat.\n",
    "- Q7: What is the \"score\" being reported? \n",
    "- Q8: Without running code, [what do you think our model is currently scoring for precision, sensitivity, and recall?]\n",
    "- Q9: Change the scoring method to one of those. [Specify them in sklearn is here.](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). How did your score change and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa6dae37-794e-4309-afd8-7ee674b50b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put answers here\n",
    "scores['test_score'].mean()  # 0\n",
    "scores['test_score']         # 5 folds\n",
    "# recall is the ratio of true positve over total number of positives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99187a-369f-4c5d-b14d-613be65f387c",
   "metadata": {},
   "source": [
    "- recall aka sensitivity : what fraction of GIVEN ACTUAL OUTCOME do we predict?\n",
    "    - defaults: # of defaults I predict default / # of actual defaults\n",
    "        - TP/ # of actual defaults\n",
    "        - 0 (never predict default!\n",
    "    - paid off: # of paid off I predict paid off / # of actual paid off\n",
    "        - TN / # of actual paid off\n",
    "        - 1!\n",
    "- precision : what fraction of GIVEN PREDICTION is correct?\n",
    "    - defaults: # of defaults I predict correctly / # of predicted defaults\n",
    "        - TP/ # of predicted defaults\n",
    "        - undefined? or: set to 0 \n",
    "    - paid off: # of paid off I predict correctly / # of predicted paid off\n",
    "        - TN / # of predicted paid off\n",
    "        - 84% paid pay back, all are predicted to --> 84%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06536071-1384-4f03-9c89-d82c6422e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DonsLaptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DonsLaptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DonsLaptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DonsLaptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DonsLaptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.36599946, 0.37235522, 0.33510518, 0.34527659, 0.39488077]),\n",
       " 'score_time': array([0.03648043, 0.03922868, 0.03423095, 0.0305016 , 0.03584886]),\n",
       " 'test_score': array([0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(logit_pipe,\n",
    "                        X_train, y_train,\n",
    "                        scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffdde4-97f8-400b-8c94-24a06b4f419c",
   "metadata": {},
   "source": [
    "### Step 6: Optimizing the model\n",
    "\n",
    "### Aka \"tuning the hyperparameters\"\n",
    "\n",
    "It seems like something about how the default values of the logit model are set is leading to a simpleton model: Predict every loan is paid back!\n",
    "\n",
    "So, the idea here is to repeat the CV above, many times, with different parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c825c6-ebb8-4dd6-9c8d-453cc20bb9c5",
   "metadata": {},
   "source": [
    "### What hyperparameters can I change?\n",
    "\n",
    "The easiest way to see all the hyperparameters in the pipeline is this: \n",
    "\n",
    "`<pipename>.get_params()`\n",
    "\n",
    "Notice how the \"C\" parameter for the LogisticRegression function is called \"`logisticregression__C`\" below? We will come back to that in  a second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a201b48c-762a-4066-98bf-e90fd628d15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(transformers=[('num_impute',\n",
       "                                    Pipeline(steps=[('simpleimputer',\n",
       "                                                     SimpleImputer()),\n",
       "                                                    ('standardscaler',\n",
       "                                                     StandardScaler())]),\n",
       "                                    ['annual_inc']),\n",
       "                                   ('cat_trans',\n",
       "                                    Pipeline(steps=[('onehotencoder',\n",
       "                                                     OneHotEncoder(drop='first'))]),\n",
       "                                    ['grade'])])),\n",
       "  ('logisticregression', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(transformers=[('num_impute',\n",
       "                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                   SimpleImputer()),\n",
       "                                                  ('standardscaler',\n",
       "                                                   StandardScaler())]),\n",
       "                                  ['annual_inc']),\n",
       "                                 ('cat_trans',\n",
       "                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                   OneHotEncoder(drop='first'))]),\n",
       "                                  ['grade'])]),\n",
       " 'logisticregression': LogisticRegression(),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('num_impute',\n",
       "   Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                   ('standardscaler', StandardScaler())]),\n",
       "   ['annual_inc']),\n",
       "  ('cat_trans',\n",
       "   Pipeline(steps=[('onehotencoder', OneHotEncoder(drop='first'))]),\n",
       "   ['grade'])],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__verbose_feature_names_out': True,\n",
       " 'columntransformer__num_impute': Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                 ('standardscaler', StandardScaler())]),\n",
       " 'columntransformer__cat_trans': Pipeline(steps=[('onehotencoder', OneHotEncoder(drop='first'))]),\n",
       " 'columntransformer__num_impute__memory': None,\n",
       " 'columntransformer__num_impute__steps': [('simpleimputer', SimpleImputer()),\n",
       "  ('standardscaler', StandardScaler())],\n",
       " 'columntransformer__num_impute__verbose': False,\n",
       " 'columntransformer__num_impute__simpleimputer': SimpleImputer(),\n",
       " 'columntransformer__num_impute__standardscaler': StandardScaler(),\n",
       " 'columntransformer__num_impute__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__num_impute__simpleimputer__copy': True,\n",
       " 'columntransformer__num_impute__simpleimputer__fill_value': None,\n",
       " 'columntransformer__num_impute__simpleimputer__keep_empty_features': False,\n",
       " 'columntransformer__num_impute__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__num_impute__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__num_impute__simpleimputer__verbose': 'deprecated',\n",
       " 'columntransformer__num_impute__standardscaler__copy': True,\n",
       " 'columntransformer__num_impute__standardscaler__with_mean': True,\n",
       " 'columntransformer__num_impute__standardscaler__with_std': True,\n",
       " 'columntransformer__cat_trans__memory': None,\n",
       " 'columntransformer__cat_trans__steps': [('onehotencoder',\n",
       "   OneHotEncoder(drop='first'))],\n",
       " 'columntransformer__cat_trans__verbose': False,\n",
       " 'columntransformer__cat_trans__onehotencoder': OneHotEncoder(drop='first'),\n",
       " 'columntransformer__cat_trans__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__cat_trans__onehotencoder__drop': 'first',\n",
       " 'columntransformer__cat_trans__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__cat_trans__onehotencoder__handle_unknown': 'error',\n",
       " 'columntransformer__cat_trans__onehotencoder__max_categories': None,\n",
       " 'columntransformer__cat_trans__onehotencoder__min_frequency': None,\n",
       " 'columntransformer__cat_trans__onehotencoder__sparse': 'deprecated',\n",
       " 'columntransformer__cat_trans__onehotencoder__sparse_output': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f1b70-ffa9-4d30-9358-eb7a10a21d03",
   "metadata": {},
   "source": [
    "### Setting up the \"hyperparameter grid\"\n",
    "\n",
    "The combination of parameters you want to try is\n",
    "- a dictionary\n",
    "- the **keys** in the dict are the hyperparameters you want to change (specifically, how the parameter is **named in the pipeline**\n",
    "- the **values** in the dict are the values for that hyperparameter you want to change\n",
    "\n",
    "For example:\n",
    "```python\n",
    "parameters =  {'logisticregression__C': [0.001,0.1,1,5]}\n",
    "```\n",
    "\n",
    "The reason I wrote the weird \"`logisticregression__C`\", is because this will help `sklearn` find the function and its parameter to change. This means that within the called \"logisticregression\" (followed by two underscores) there is a parameter called \"C\".\n",
    "\n",
    "Similarly, within the \"columntransformer\" step, there is a \"num_impute\" step, which has a \"simpleimputer\" step, which is a function that has a parameter called \"strategy\".\n",
    "\n",
    "Thus, if you want to try other strategies for filling blank numbers in, \"`'columntransformer__num_impute__simpleimputer__strategy'`\" is what you need.\n",
    "\n",
    "Thus:\n",
    "```python\n",
    "parameters =  {'logisticregression__C': [0.001,0.1,1,5],\n",
    "              'columntransformer__num_impute__simpleimputer__strategy' : ['mean','median']}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c64759-217a-48fe-acc2-80e60644c7d1",
   "metadata": {},
   "source": [
    "### All together now...\n",
    "\n",
    "1. Set up your parameter grid\n",
    "1. Make a \"super estimator\" object with `GridSearchCV`. This just runs cross_validate for every combination of parameters in the grid. (Below, 2x3=6 combinations.)\n",
    "1. Just like CV, use `.fit()` to run the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c126e83-44f9-4544-a87f-0aebc9c21241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyper param grid - what params in a pipeline do you want to change?\n",
    "# a dictionary. keys are things to change in pipeline, values are what to try for that param\n",
    "# key: <stepname>__<parametername>\n",
    "\n",
    "parameters =  {'logisticregression__C': [0.1,1,5], \n",
    "              'columntransformer__num_impute__simpleimputer__strategy' : ['mean','median']}\n",
    "\n",
    "#     find optimal hyper params (gridsearchcv)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logit_pipe, \n",
    "                           param_grid = parameters,\n",
    "                           cv = 5,\n",
    "                           scoring=['recall','f1'],\n",
    "                           # pick your fav score, or none\n",
    "                           refit = False\n",
    "                           )\n",
    "\n",
    "# .fit() runs the CV for all combos of param_grid \n",
    "results = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#     save pipeline with optimal params in place\n",
    "#     (Note: you should spend time interrogating model predictions, plotting and printing.\n",
    "#     Does the model struggle predicting certain obs? Excel at some?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b90668-1012-4b05-ace5-b8f738b70d8f",
   "metadata": {},
   "source": [
    "### What to do after that?\n",
    "\n",
    "[The \"outputs\" of the grid search are the attributes of the results object, as listed here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "- Q10: Output the CV results\n",
    "    - Bonus: Do it as a dataframe\n",
    "- Q11: Make the grid search output recall, sensitivity, f1, and accuracy \n",
    "\n",
    "---\n",
    "\n",
    "Now, here is what I'd _**like**_ to ask you:\n",
    "\n",
    "- Q12: Which of these models would you choose, taking into account the bias-variance tradeoff? Discuss whether these models are high bias or not, and whether they are high variance or not.\n",
    "- Q13: Outline how we might adjust our model here to improve its performance\n",
    "\n",
    "**Except: Don't answer those for today's (bad) logit model. I've \"hidden\" something from you about why this model is performing so poorly. Think of this as \"a case study in miniature\" about how \"black boxes\" can make dealing with ML models impenetrable.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "093510f4-beaf-468c-b891-fd1ea6a48311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_columntransformer__num_impute__simpleimputer__strategy</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338096</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 0.1}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322618</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 1}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325380</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>mean</td>\n",
       "      <td>5</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 5}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.329071</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>median</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 0.1}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350391</td>\n",
       "      <td>0.019505</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>median</td>\n",
       "      <td>1</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 1}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.358551</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.044138</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>median</td>\n",
       "      <td>5</td>\n",
       "      <td>{'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 5}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.338096      0.038793         0.042502        0.003579   \n",
       "1       0.322618      0.012542         0.045872        0.001850   \n",
       "2       0.325380      0.002497         0.045296        0.002711   \n",
       "3       0.329071      0.008232         0.043119        0.002813   \n",
       "4       0.350391      0.019505         0.043140        0.002749   \n",
       "5       0.358551      0.017346         0.044138        0.004435   \n",
       "\n",
       "  param_columntransformer__num_impute__simpleimputer__strategy  \\\n",
       "0                                                         mean   \n",
       "1                                                         mean   \n",
       "2                                                         mean   \n",
       "3                                                       median   \n",
       "4                                                       median   \n",
       "5                                                       median   \n",
       "\n",
       "  param_logisticregression__C  \\\n",
       "0                         0.1   \n",
       "1                           1   \n",
       "2                           5   \n",
       "3                         0.1   \n",
       "4                           1   \n",
       "5                           5   \n",
       "\n",
       "                                                                                               params  \\\n",
       "0    {'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 0.1}   \n",
       "1      {'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 1}   \n",
       "2      {'columntransformer__num_impute__simpleimputer__strategy': 'mean', 'logisticregression__C': 5}   \n",
       "3  {'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 0.1}   \n",
       "4    {'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 1}   \n",
       "5    {'columntransformer__num_impute__simpleimputer__strategy': 'median', 'logisticregression__C': 5}   \n",
       "\n",
       "   split0_test_recall  split1_test_recall  split2_test_recall  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "5                 0.0                 0.0                 0.0   \n",
       "\n",
       "   split3_test_recall  split4_test_recall  mean_test_recall  std_test_recall  \\\n",
       "0                 0.0                 0.0               0.0              0.0   \n",
       "1                 0.0                 0.0               0.0              0.0   \n",
       "2                 0.0                 0.0               0.0              0.0   \n",
       "3                 0.0                 0.0               0.0              0.0   \n",
       "4                 0.0                 0.0               0.0              0.0   \n",
       "5                 0.0                 0.0               0.0              0.0   \n",
       "\n",
       "   rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1  \\\n",
       "0                 1             0.0             0.0             0.0   \n",
       "1                 1             0.0             0.0             0.0   \n",
       "2                 1             0.0             0.0             0.0   \n",
       "3                 1             0.0             0.0             0.0   \n",
       "4                 1             0.0             0.0             0.0   \n",
       "5                 1             0.0             0.0             0.0   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0             0.0             0.0           0.0          0.0             1  \n",
       "1             0.0             0.0           0.0          0.0             1  \n",
       "2             0.0             0.0           0.0          0.0             1  \n",
       "3             0.0             0.0           0.0          0.0             1  \n",
       "4             0.0             0.0           0.0          0.0             1  \n",
       "5             0.0             0.0           0.0          0.0             1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put answers here for Q10 and Q11\n",
    "pd.DataFrame(results.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
