{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b3e546-296c-4d7e-b8c3-cac7280db97f",
   "metadata": {},
   "source": [
    "# Pipelines (preprocessing to estimator), CV, Gridsearch\n",
    "\n",
    "- [ ] how to do: preprocessing (with `ColumnTransformer`)\n",
    "- [ ] how to examine: preprecessing\n",
    "- [ ] how to do: pipelines + cross validation + scoring\n",
    "    - `make_pipeline()` with preprocessing and estimator\n",
    "    - examine pipeline elements \n",
    "    - fit and predict using the pipeline (not CV)\n",
    "    - examine the pipeline using CV (using the cv function and examining its output)\n",
    "- [ ] scoring vocab: recall/sensitivity, precision, specificity, accuracy, \n",
    "- [ ] how to do: optimizing a pipeline by \"tuning the hyperparameters\"\n",
    "    - hyperparameters are the parameters of functions/estimators in the steps in your pipeline\n",
    "    - set up and use `gridsearchCV`\n",
    "    - examine output of `gridsearchCV`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8ccb8c-f508-4022-bbca-f3a03311a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from df_after_transform import df_after_transform\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")  # display='text' is the default\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000, 'display.max_rows', 50, 'display.max_columns', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdaf8d-899f-41f5-b520-79da9c5284d5",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5771be6-0588-440b-b738-5a55f50bb6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d81a81b-7e5d-4483-a987-90e2fd8c70d3",
   "metadata": {},
   "source": [
    "## Create the training and holdout samples\n",
    "\n",
    "Split your data into test and train. Your options:\n",
    "- [sklearn has some built in splitters](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "    - These are rarely the best optios for real world data. Prediction is often about the future!\n",
    "- [`test_train_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) can do basic splits, but may not be appropriate\n",
    "    - _test_ is the typical sklearn vernacular, on the website I call this this holdout sample\n",
    "- You can just keep the most recent time period of your samples in the holdout and put the rest into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9807f9-3c31-48bd-b380-701d5f99b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "False    113780\n",
      "True      21024\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('inputs/2013_subsample.zip')\n",
    "\n",
    "# split to test and train (what we call the \"test\" subset here is the \"holdout\" data)\n",
    "\n",
    "# first let's separate y from X (as is typically done)\n",
    "y = loans.loan_status == 'Charged Off'\n",
    "print(y.value_counts()) # rougly 16% ish \n",
    "loans = loans.drop('loan_status',axis=1)\n",
    "\n",
    "# stratify will make sure that test/train both have equal fractions of outcome\n",
    "# stratify means that in test and train, the fraction of charge offs is equal\n",
    "# test_size means 20% of data is in the holdout\n",
    "# random_state is a seed meaning we all have the exact same split (reproducible!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans, y, stratify=y, test_size=.2, random_state=0)\n",
    "\n",
    "# I would save X_train and y_train in a folder\n",
    "# I would save X_test and y_test in a holdout folder\n",
    "\n",
    "del y_test # paranoid step - ensures we can't look at the holdout data too soon\n",
    "del X_test\n",
    "del loans  # not paranoid! easy to use this by accident "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7e8a4-0496-4706-8c20-4ab4b4754642",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "On the **TRAINING DATA ONLY**: \n",
    "- do lots of EDA\n",
    "- look for missing values, which variables are what type, and outliers \n",
    "- figure out how you'd clean the data (imputation, scaling, encoding categorical vars)\n",
    "- these lessons will go into the preprocessinG portion of your pipeline \n",
    "- PRO TIP: `pandas-profiling` and `dabl` build automated reports. Which is nice, but remember you need to examine them closely! **There is no shortcut for EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecffc0-43bb-4b20-836e-4a9b72922635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport # now use ydata-profiling\n",
    "# \n",
    "# profile = ProfileReport(pd.concat([y_train, X_train], axis=1), \n",
    "#                         title='Lending Club Profiling Report',\n",
    "#                         html={'style':{'full_width':True}}) \n",
    "# profile.to_file(\"inputs/lending_club_EDA_training.html\") # can take a minute or two with this dataset size. Let's look at the one I uploaded...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e2142c4-feca-44a2-ba23-ec7d19a8bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term\n",
       " 36 months    80314\n",
       " 60 months    27529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.isna().mean()\n",
    "# X_train['purpose'].value_counts() \n",
    "# X_train['emp_title']\n",
    "# X_train[X_train['emp_title'].isna()]['purpose'].value_counts()\n",
    "X_train['issue_d'].str[-4:].value_counts()\n",
    "X_train['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2c6232f-ac94-4f4a-a18b-ea4a912d0971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107843, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2d066-47ba-48c1-9099-f29cbda0d9b1",
   "metadata": {},
   "source": [
    "EDA findings\n",
    "- id is the unit identifier AND it is unique (no duplicate rows) \n",
    "- date: 2013 for all loans\n",
    "- unit: a loan\n",
    "- 32 vars, 107k loans \n",
    "- variables: - missing, categorical, info about continuous vars, outliers\n",
    "   - 5% of cells are missing\n",
    "   - member ID always missing, desc 65%, emp length and title halfish, 2 vars with a few missing\n",
    "   - application_type is meaningless (always individ)\n",
    "   - outliers in income: 6k to 6m\n",
    "   - some are unemployed maybe? what does missing emp_title mean?\n",
    "   - loan amounts: 14k mean, 35k max, min 1k  (corr with installment)\n",
    "   - 36 or 60 months "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90522f-d069-4649-ad7c-32aa03ae3d4a",
   "metadata": {},
   "source": [
    "## NOW LET'S LEARN EACH PART OF \"Optimize a series of models\" FROM THE TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad9a34-752b-4282-a7d0-ce03e86ae572",
   "metadata": {},
   "source": [
    "### Steps 1 and 2: Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bedb4dc4-f531-4f95-be76-9e3e8e30b571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num_impute&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;annual_inc&#x27;, &#x27;dti, fico_range_high&#x27;]),\n",
       "                                (&#x27;cat_trans&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;grade&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_impute&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;annual_inc&#x27;, &#x27;dti, fico_range_high&#x27;]),\n",
       "                                (&#x27;cat_trans&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;grade&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_impute</label><div class=\"sk-toggleable__content\"><pre>[&#x27;annual_inc&#x27;, &#x27;dti, fico_range_high&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_trans</label><div class=\"sk-toggleable__content\"><pre>[&#x27;grade&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_impute',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer()),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['annual_inc', 'dti, fico_range_high']),\n",
       "                                ('cat_trans',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='first'))]),\n",
       "                                 ['grade'])])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up pipeline to clean each type of variable (1 pipe per var type)\n",
    "\n",
    "numer_pipe = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                           StandardScaler()) \n",
    "\n",
    "cat_pipe   = make_pipeline(OneHotEncoder(drop='first'))\n",
    "# drop first for reg like estimators, keep for others , eg,  trees \n",
    "\n",
    "# combine those pipes into \"preprocess\" pipe\n",
    "\n",
    "preproc_pipe = ColumnTransformer(  \n",
    "    [ \n",
    "        # a list of tuples \n",
    "        # tuple: name for step, which pipe for this step, which vars \n",
    "        (\"num_impute\", numer_pipe, ['annual_inc','dti, fico_range_high']),\n",
    "        (\"cat_trans\", cat_pipe, ['grade'])\n",
    "    ]\n",
    "    , \n",
    "    remainder = 'drop' \n",
    ")\n",
    "\n",
    "numer_pipe # prints out dialog, click the pipeline to show full steps \n",
    "cat_pipe\n",
    "preproc_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9deeb97-af7d-4068-a75d-cecf2b36f5a1",
   "metadata": {},
   "source": [
    "_Note: You can have multiple \"numeric pipes\" or \"cat pipes\" if you think some number variables should receive different treatments, which is very common!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da2b19a-887d-404f-b212-dcfb527b6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 columns in the preprocessed data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>121.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_B</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_C</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_D</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_E</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_F</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_G</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  mean   std   min   25%   50%   75%     max\n",
       "annual_inc  107843.0  0.00  1.00 -1.36 -0.55 -0.19  0.32  121.55\n",
       "grade_B     107843.0  0.33  0.47  0.00  0.00  0.00  1.00    1.00\n",
       "grade_C     107843.0  0.28  0.45  0.00  0.00  0.00  1.00    1.00\n",
       "grade_D     107843.0  0.15  0.36  0.00  0.00  0.00  0.00    1.00\n",
       "grade_E     107843.0  0.07  0.25  0.00  0.00  0.00  0.00    1.00\n",
       "grade_F     107843.0  0.03  0.18  0.00  0.00  0.00  0.00    1.00\n",
       "grade_G     107843.0  0.01  0.08  0.00  0.00  0.00  0.00    1.00"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# hot tip: check out what this preprocessing does before you continue!\n",
    "###########\n",
    "\n",
    "from df_after_transform import df_after_transform\n",
    "\n",
    "preproc_df = df_after_transform(preproc_pipe,X_train)\n",
    "print(f'There are {preproc_df.shape[1]} columns in the preprocessed data.')\n",
    "preproc_df.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "911b0112-18f7-4f9c-a52a-088d6a1ed366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.569106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.952298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.831290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.237613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107838</th>\n",
       "      <td>-0.468266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107839</th>\n",
       "      <td>0.035933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107840</th>\n",
       "      <td>-0.750618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107841</th>\n",
       "      <td>0.580468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107842</th>\n",
       "      <td>0.338452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107843 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        annual_inc  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G\n",
       "0        -0.569106      0.0      1.0      0.0      0.0      0.0      0.0\n",
       "1        -0.952298      0.0      1.0      0.0      0.0      0.0      0.0\n",
       "2        -0.024571      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "3        -0.831290      0.0      1.0      0.0      0.0      0.0      0.0\n",
       "4         0.237613      0.0      0.0      0.0      0.0      0.0      0.0\n",
       "...            ...      ...      ...      ...      ...      ...      ...\n",
       "107838   -0.468266      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "107839    0.035933      0.0      1.0      0.0      0.0      0.0      0.0\n",
       "107840   -0.750618      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "107841    0.580468      1.0      0.0      0.0      0.0      0.0      0.0\n",
       "107842    0.338452      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "\n",
       "[107843 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c09ac5-fa1a-47fd-bd15-8af652ef4c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "1. How many observations for `annual_inc` were non-missing before the processing? Does our imputation choice here we make a small or large impact?\n",
    "1. How many values of `grade` was there in the data before and after `preproc_pipe`? \n",
    "1. Above, revise `preproc_pipe` to include another continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24b6dc05-99ea-49bd-87ad-d18072190b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answers here\n",
    "X_train['annual_inc'].count(), len(X_train), X_train['annual_inc'].isna().sum()\n",
    "len(X_train['grade'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf6c75-fe7b-49a6-8ad5-a11ebd62d54b",
   "metadata": {},
   "source": [
    "Answers:\n",
    "1. Zero. Doesn't matter for THIS variable in THIS data\n",
    "1. Seven before - 6 after\n",
    "1. dti, fico_range_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0ae66-ac2e-4808-b4aa-46ba4991e356",
   "metadata": {},
   "source": [
    "### Prof demo: Fitting and using ONE model\n",
    "\n",
    "Warning: This is not best practice to do on the whole training sample. The point here is to simply show you how to estimate and use a model.\n",
    "\n",
    "_(The only time you fit a model on the whole training sample is the VERY end of the template, right before you check to see how it does on the holdout.)_\n",
    "\n",
    "Steps: https://ledatascifi.github.io/ledatascifi-2022/content/05/04c_onemodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7cb00-5ba2-4c3a-a3f6-39a83f5656dc",
   "metadata": {},
   "source": [
    "To fit the model: `<model>.fit(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880e9f2-2c72-4e84-b995-908fd503cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (\"instantiate\") the estimator class with some hyperparameters,\n",
    "# note: the hypermeters are whatever is inside the \"()\"\n",
    "# assign this instance of the estimator to an object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# fit the model to the data: <model>.fit(X,y)\n",
    "# note: I'm only using annual income here for illustration\n",
    "logit.fit(X_train[['annual_inc']], \n",
    "          y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34622e51-07a4-4ebc-9b6b-e8ae940ee7ce",
   "metadata": {},
   "source": [
    "To use the model: `<model>.predict(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3fcc4-b5f2-4242-8781-2bdf71c4f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates predicted values \n",
    "y_pred = logit.predict(X_train[['annual_inc']],)\n",
    "\n",
    "print(f'''\n",
    "% predicted as charge offs: {round(100*(y_pred == 1).mean(),2)}\n",
    "Accuracy:                   {round(100*(y_pred == y_train).mean(),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f9e05-1695-4711-a4bb-d5c4db4b8dcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "- Q4: Let's estimate a different logit model, and see if the accuracy or the number of predictions of charge offs changes. [This time change the penalty OR the value of \"C\".](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af2527-5d12-47d1-adb9-20fc836a3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12edbc63-87fc-4c75-89ef-9ffa36142a90",
   "metadata": {},
   "source": [
    "### Steps 3, 4, and 5: Pipelines, CV, and model evaluation (scoring)\n",
    "\n",
    "Making a pipeline is easy: `make_pipeline` will put steps together for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77585a80-f73c-48b1-babd-7d6cef833911",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = make_pipeline(preproc_pipe, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81d990-05ff-4d1e-ab7e-a9e660669ee0",
   "metadata": {},
   "source": [
    "A pipeline is an object that stores its steps (and steps within steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b93e3-9e04-4e41-8e1a-c0506fbfa1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704d1f0-07fc-4834-b7c0-5e2776d95160",
   "metadata": {},
   "source": [
    "Fitting the model and using it is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7616d7-8203-4f3d-b5aa-8952212f8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe.fit(X_train, y_train) \n",
    "y_pred = logit_pipe.predict(X_train)\n",
    "\n",
    "print(f'''\n",
    "% predicted as charge offs: {round(100*(y_pred == 1).mean(),2)}\n",
    "Accuracy:                   {round(100*(y_pred == y_train).mean(),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247024f0-3bcb-4b66-a4a1-a8444eb530f4",
   "metadata": {},
   "source": [
    "But the better idea is to see how that model does on different \"folds\" of the data: CROSS VALIDATION.\n",
    "\n",
    "The [`cross_validate` (function docs here)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html?highlight=cross_validate#sklearn.model_selection.cross_validate) makes this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c4666-6da0-4d77-8de4-0a8b19ab9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(logit_pipe,\n",
    "                        X_train, y_train,\n",
    "                        scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd878ec-0312-4fb2-8b9b-cab993ec233f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISES\n",
    "\n",
    "- Q5: What is the average score of this model in the folds?\n",
    "- Q6: How many folds did we use above (by default). Change to 10 folds and repeat.\n",
    "- Q7: What is the \"score\" being reported? \n",
    "- Q8: Without running code, [what do you think our model is currently scoring for precision, sensitivity, and recall?]\n",
    "- Q9: Change the scoring method to one of those. [Specify them in sklearn is here.](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). How did your score change and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6dae37-794e-4309-afd8-7ee674b50b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffdde4-97f8-400b-8c94-24a06b4f419c",
   "metadata": {},
   "source": [
    "### Step 6: Optimizing the model\n",
    "\n",
    "### Aka \"tuning the hyperparameters\"\n",
    "\n",
    "It seems like something about how the default values of the logit model are set is leading to a simpleton model: Predict every loan is paid back!\n",
    "\n",
    "So, the idea here is to repeat the CV above, many times, with different parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c825c6-ebb8-4dd6-9c8d-453cc20bb9c5",
   "metadata": {},
   "source": [
    "### What hyperparameters can I change?\n",
    "\n",
    "The easiest way to see all the hyperparameters in the pipeline is this: \n",
    "\n",
    "`<pipename>.get_params()`\n",
    "\n",
    "Notice how the \"C\" parameter for the LogisticRegression function is called \"`logisticregression__C`\" below? We will come back to that in  a second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201b48c-762a-4066-98bf-e90fd628d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f1b70-ffa9-4d30-9358-eb7a10a21d03",
   "metadata": {},
   "source": [
    "### Setting up the \"hyperparameter grid\"\n",
    "\n",
    "The combination of parameters you want to try is\n",
    "- a dictionary\n",
    "- the **keys** in the dict are the hyperparameters you want to change (specifically, how the parameter is **named in the pipeline**\n",
    "- the **values** in the dict are the values for that hyperparameter you want to change\n",
    "\n",
    "For example:\n",
    "```python\n",
    "parameters =  {'logisticregression__C': [0.001,0.1,1,5]}\n",
    "```\n",
    "\n",
    "The reason I wrote the weird \"`logisticregression__C`\", is because this will help `sklearn` find the function and its parameter to change. This means that within the called \"logisticregression\" (followed by two underscores) there is a parameter called \"C\".\n",
    "\n",
    "Similarly, within the \"columntransformer\" step, there is a \"num_impute\" step, which has a \"simpleimputer\" step, which is a function that has a parameter called \"strategy\".\n",
    "\n",
    "Thus, if you want to try other strategies for filling blank numbers in, \"`'columntransformer__num_impute__simpleimputer__strategy'`\" is what you need.\n",
    "\n",
    "Thus:\n",
    "```python\n",
    "parameters =  {'logisticregression__C': [0.001,0.1,1,5],\n",
    "              'columntransformer__num_impute__simpleimputer__strategy' : ['mean','median']}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c64759-217a-48fe-acc2-80e60644c7d1",
   "metadata": {},
   "source": [
    "### All together now...\n",
    "\n",
    "1. Set up your parameter grid\n",
    "1. Make a \"super estimator\" object with `GridSearchCV`. This just runs cross_validate for every combination of parameters in the grid. (Below, 2x3=6 combinations.)\n",
    "1. Just like CV, use `.fit()` to run the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c126e83-44f9-4544-a87f-0aebc9c21241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyper param grid - what params in a pipeline do you want to change?\n",
    "# a dictionary. keys are things to change in pipeline, values are what to try for that param\n",
    "# key: <stepname>__<parametername>\n",
    "\n",
    "parameters =  {'logisticregression__C': [0.1,1,5], \n",
    "              'columntransformer__num_impute__simpleimputer__strategy' : ['mean','median']}\n",
    "\n",
    "#     find optimal hyper params (gridsearchcv)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logit_pipe, \n",
    "                           param_grid = parameters,\n",
    "                           cv = 10\n",
    "                           )\n",
    "\n",
    "results = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#     save pipeline with optimal params in place\n",
    "#     (Note: you should spend time interrogating model predictions, plotting and printing.\n",
    "#     Does the model struggle predicting certain obs? Excel at some?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b90668-1012-4b05-ace5-b8f738b70d8f",
   "metadata": {},
   "source": [
    "### What to do after that?\n",
    "\n",
    "[The \"outputs\" of the grid search are the attributes of the results object, as listed here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "- Q10: Output the CV results\n",
    "    - Bonus: Do it as a dataframe\n",
    "- Q11: Make the grid search output recall, sensitivity, f1, and accuracy \n",
    "\n",
    "---\n",
    "\n",
    "Now, here is what I'd _**like**_ to ask you:\n",
    "\n",
    "- Q12: Which of these models would you choose, taking into account the bias-variance tradeoff? Discuss whether these models are high bias or not, and whether they are high variance or not.\n",
    "- Q13: Outline how we might adjust our model here to improve its performance\n",
    "\n",
    "**Except: Don't answer those for today's (bad) logit model. I've \"hidden\" something from you about why this model is performing so poorly. Think of this as \"a case study in miniature\" about how \"black boxes\" can make dealing with ML models impenetrable.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093510f4-beaf-468c-b891-fd1ea6a48311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put answers here for Q10 and Q11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
